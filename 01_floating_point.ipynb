{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f828b1e2-5802-4815-ba18-7cae0e60b48e",
   "metadata": {},
   "source": [
    "# Know your (computer's) limits: Floating point arithmetic\n",
    "\n",
    "*(Jupyter notebook by Simone Brugiapaglia)*\n",
    "\n",
    "In this notebook we will illustrate some basic notions and experiments on floating point arithmetic. \n",
    "\n",
    "The main reference is Chapter 9 of the book\n",
    "\n",
    "*Q. Kong, T. Siauw, and A. M. Bayen. Python Programming and Numerical Methods: A Guide for Engineers and Scientists. Academic Press, 2021. (https://pythonnumericalmethods.berkeley.edu/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7225ff3f-2eff-4965-82a1-3919670a3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all modules necessary to run this notebook\n",
    "import sys\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736f7e3-2fc3-40a0-907e-9ea7eab63393",
   "metadata": {},
   "source": [
    "## Floating point numbers specifics (IEEE 754 standard)\n",
    "\n",
    "A floating point number $n$ can be represented as\n",
    "$$\n",
    "n = (-1)^s \\cdot 2^{c-1023} \\cdot (1+f),\n",
    "$$\n",
    "where $s$ is the *sign indicator*, $c$ is the *characteristic* or *exponent* and $f$ is the *mantissa* or *fraction*. In the IEEE 754 standard for double precision arithmetic (see https://en.wikipedia.org/wiki/IEEE_754) a floating point number is stored using 64 bits, organized as follows: \n",
    "- 1 bit for the sign $s \\in \\{0,1\\}$\n",
    "- 11 bits for the characteristic $c \\in \\{0,1, \\ldots, 2^{11}-1 = 2047\\}$\n",
    "- 52 bits for the mantissa (in binary representation) $f = 0.b_1b_2\\ldots b_{52} \\in [0, 1-2^{-52}]$ (where $b_j \\in\\{0,1\\}$ are binary digits)\n",
    "\n",
    "Note that $c = 0$ is reserved to represent the number $n=0$ and so-called *subnormal numbers* (https://en.wikipedia.org/wiki/Subnormal_number). In addition, $c = 2047$ is reserved for the special values `nan` (not a number) and `inf`.\n",
    "\n",
    "In Python, we can obtain information about floating point numbers specifics using the `sys` module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ef14e0-103f-4a0e-a68a-9d2671756049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.float_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae3063-e2be-4d96-a00b-0333f23d5e7a",
   "metadata": {},
   "source": [
    "### Smallest and largest floating point numbers\n",
    "\n",
    "One could easily check what the largest and smallest double precision floating point numbers are.\n",
    "\n",
    "Recalling that $c = 2047$ is reserved for special values, the largest flating point number is $2^{1023}\\cdot(2-2^{-52})$, corresponding to $c = 2046$ and $f = 1-2^{-52}$. We can also compute it using the command `sys.float_info.max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a1c1af-7450-4a8c-b42c-acec79766a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7976931348623157e+308\n",
      "1.7976931348623157e+308\n"
     ]
    }
   ],
   "source": [
    "c = 2046       # characteristic\n",
    "f = 1-2**(-52) # mantissa\n",
    "print(2**(c-1023)*(1+f))  # largest floating point number, computed using the definition\n",
    "\n",
    "print(sys.float_info.max) # largest floating point number, computed using the sys module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8db865-944c-4fa8-aed9-9b1f0f3b9486",
   "metadata": {},
   "source": [
    "Similary, one can compute the smallest floatin point number and show that it concides with `sys.float_info.min` (note that subnormal numbers, corresponding to the exponent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e70fc4-1a4e-404d-ba25-ad42cfac54b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2250738585072014e-308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2250738585072014e-308"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 1\n",
    "f = 0\n",
    "print(2**(c-1023)*(1+f)) # largest floating point number, computed using the definition\n",
    "sys.float_info.min       # largest floating point number, computed using the sys module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76caf21d-25d1-4a49-95ff-6e912603076e",
   "metadata": {},
   "source": [
    "### Gap between floating point numbers\n",
    "\n",
    "Note that real numbers have no gaps between them, since they contiuously fill up the real line. However, this is not the case for floating point numbers. In fact, there is always a nonzero gap between two consecutive floating point numbers. In practice, this means that, unlike the line of real numbers, the set of floating point numbers has a *finite* resolution. The gap between a given number and its closest neighbor can be computed using the Python command `np.spacing`, inluded in the `numpy` library. \n",
    "\n",
    "Let's compute the gap between `1` and its closest floating point number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ecf0815-e922-4984-8b94-27795caa2c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.spacing(1) # compute the gap between 1 and its closest floating point number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83390e72-069c-44cd-bd3f-64ebca2de3c7",
   "metadata": {},
   "source": [
    "This means that if we add `2.220446049250313e-16` to `1`, we will get a number different from `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d753ad18-2a7b-4256-bc04-c6e89f043518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "one_plus_small = 1 + np.spacing(1)\n",
    "print(one_plus_small)      # add a small floating point number to 1, larger than its gap\n",
    "print(one_plus_small == 1) # check if the result is equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10751c99-693d-4ab5-b2ef-c655625613f2",
   "metadata": {},
   "source": [
    "However, it we add, for example, one half of `2.220446049250313e-16` to `1`, the result will be inaccurate, since there is not enough space to represent that number in floating point arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa464fd-d551-41d2-9219-5a636ef36cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "one_plus_smaller = 1 + np.spacing(1)/2\n",
    "print(one_plus_smaller)      # add a small floating point number to 1, smaller than its gap\n",
    "print(one_plus_smaller == 1) # check if the result is equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c237191-cd51-40a8-8a5d-c2451c772937",
   "metadata": {},
   "source": [
    "## Round-off errors\n",
    "\n",
    "The previous examples where we add a very small number to `1` and get an inaccurate result is an example of *round-off error*. The fact that we perform operations in floating point arithmetic constantly introduces errors. \n",
    "\n",
    "The first kind of round-off error is the *representation error* committed by storing numbers that are not floating point numbers in memory. Examples include $e$, $\\pi$, but also rational numbers such as $1/3$ or $3/7$. For example, $e$ has infinitely-many non periodic digits in its decimal representation. However, its floating point representation can only contain a finite number of digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c0365e-ad6c-4bfa-a5d9-93bf7c267d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "print(math.e) # standard way to use e in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45146d9e-1e45-488e-b76b-7fcadff2571f",
   "metadata": {},
   "source": [
    "We could try to define a new variable contaning more digits of $e$ (see https://apod.nasa.gov/htmltest/gifcity/e.1mil), but the result will be truncated and only 64 bits of this number will be stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a4e894-8b76-4a9a-b644-1f6d7932c993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.718281828459045\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# More digits of e (from https://apod.nasa.gov/htmltest/gifcity/e.1mil)\n",
    "e_with_more_digits = 2.7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274274663919320\n",
    "print(e_with_more_digits)\n",
    "print(e_with_more_digits == math.e) # Check that our representation of e with more digit is equal to the stardard one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f5499-89d5-4a5a-96c1-31897605d511",
   "metadata": {},
   "source": [
    "Another type of round-off error is generated by floating point arithmetic. For example, $\\cos(\\pi/2)$ is not exactly equal to $0$ in because the computation of this function depends on floating point arithmetic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4198a093-e581-4f2c-b4ee-2825c5d125e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.123233995736766e-17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.cos(math.pi / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0276270-321e-4c2a-b133-7f4b6636f851",
   "metadata": {},
   "source": [
    "Let's consider another illustrative example where simple arithmetic operations can cause round-off errors. For example, we know that the expression $x + 1/x$ is always a number different from $x$, for any $x \\neq 0$. However, the situation in floating point arithmetic is different and depends on the size of $x$... If $x$ is too large, then the sum $x + 1/x$ will yield a cancellation error, resulting in this number being equal to $x$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76c7b7a-a0ee-441d-965b-f5d2142084ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = 1e8\n",
    "print(x == x + 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526b9f69-516f-4f73-ab69-18cc9d86a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = 1e9\n",
    "print(x == x + 1/x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ff27d-f54e-4b98-b667-5a163e01e9b2",
   "metadata": {},
   "source": [
    "### Two ways of computing the sample variance\n",
    "The sample variance of a sample $x_1, \\ldots, x_n$ is defined as \n",
    "$$\n",
    "s^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2, \\quad \\text{where } \\bar{x} = \\frac1n \\sum_{i=1}^n x_i,\n",
    "$$\n",
    "and $\\bar{x}$ is the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c520cc4-8642-4910-8ebe-ceeb59831097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean = 0.4906384897802641\n",
      "sample variance (1st formula) = 0.08591274059325583\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "x = np.random.rand(n,1) # generate n random numbers uniformly distributed in [0,1]\n",
    "sample_mean = np.sum(x) / n\n",
    "sample_var = np.sum( (x - sample_mean)**2 ) / (n-1)\n",
    "\n",
    "print('sample mean =', sample_mean)\n",
    "print('sample variance (1st formula) =', sample_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39372adf-82a9-46c6-9033-c9ba7824850f",
   "metadata": {},
   "source": [
    "An equivalent formula for the sample variance is \n",
    "$$\n",
    "s^2 = \\frac{1}{n-1} \\left( \\sum_{i=1}^n x_i^2 - n \\bar{x}^2\\right).\n",
    "$$\n",
    "(Try to prove that they are equivalent!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8a1211f-a7ed-494f-b981-0a5c9e51966b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample variance (2nd formula) = 0.08591274059325575\n"
     ]
    }
   ],
   "source": [
    "sample_var_2 = (np.sum(x**2) - n * sample_mean**2 ) / (n-1)\n",
    "print('sample variance (2nd formula) =',sample_var_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1eedd-a4dd-4c00-84e2-912a5f21b277",
   "metadata": {},
   "source": [
    "The results are essentially equivalent. However, if we add a very large number to the sample observations, only the first formula remains accurate. (Note that adding a constant number to the sample observations should only change its mean, not its variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d958cd-c35c-4dbc-9468-1ca15df5a234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean = 10000000000.490639\n",
      "sample variance (1st formula) = 0.0859127453663172\n",
      "sample variance (2nd formula) = 0.0\n"
     ]
    }
   ],
   "source": [
    "x = x + 1e10\n",
    "sample_mean = np.sum(x) / n\n",
    "sample_var = np.sum( (x - sample_mean)**2 ) / (n-1)\n",
    "sample_var_2 = (np.sum(x**2) - n * sample_mean**2 ) / (n-1)\n",
    "sample_var_2\n",
    "\n",
    "print('sample mean =', sample_mean)\n",
    "print('sample variance (1st formula) =', sample_var)\n",
    "print('sample variance (2nd formula) =', sample_var_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c4de3-cd85-4a8e-a59f-49f762a697e8",
   "metadata": {},
   "source": [
    "The second formula is subject to huge round-off error. Be careful, this could lead to false discoveries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d63579-8700-4a2d-bb97-59bc448b16c8",
   "metadata": {},
   "source": [
    "## Recommended problems\n",
    "\n",
    "1. After reading Chapter 9 of \n",
    "\n",
    "    *Q. Kong, T. Siauw, and A. M. Bayen. Python Programming and Numerical Methods: A Guide for Engineers and Scientists. Academic Press, 2021. (https://pythonnumericalmethods.berkeley.edu/)*\n",
    "\n",
    "    I invite you to work on the following problems: 1, 2, 6, 7.\n",
    "\n",
    "2. Also, have fun trying to find examples where round-off errors leads to unexpected results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42778323-d536-480b-9dde-74962caf15c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
